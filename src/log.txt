nohup: ignoring input
srun: job 284337 queued and waiting for resources
srun: job 284337 has been allocated resources
Using backend: pytorch
2021/07/01 21:15:52: [ RGIN(
  (g_v_enc): Embedding(64, 12)
  (g_vl_enc): Embedding(20, 10)
  (p_v_enc): Embedding(64, 12)
  (p_vl_enc): Embedding(20, 10)
  (g_attr_enc): Embedding(4, 4)
  (p_attr_enc): Embedding(4, 4)
  (vl_flt): MaxGatedFilterNet()
  (g_vl_emb): EquivariantEmbedding(
    (emb_layer): Linear(in_features=10, out_features=128, bias=False)
  )
  (p_vl_emb): EquivariantEmbedding(
    (emb_layer): Linear(in_features=10, out_features=128, bias=False)
  )
  (g_net): ModuleList(
    (graph_rgi0): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
    (graph_rgi1): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
    (graph_rgi2): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
  )
  (p_net): ModuleList(
    (graph_rgi0): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
    (graph_rgi1): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
    (graph_rgi2): RGINLayer(
      (rgc_layer): RelGraphConv(
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): LeakyReLU(negative_slope=0.18181818181818182)
        (2): Linear(in_features=128, out_features=128, bias=True)
        (3): LeakyReLU(negative_slope=0.18181818181818182)
      )
      (drop): Dropout(p=0.2, inplace=False)
    )
  )
  (predict_net): SumPredictNet(
    (act): LeakyReLU(negative_slope=0.18181818181818182)
    (drop): Dropout(p=0.2, inplace=False)
    (p_layer): Linear(in_features=151, out_features=128, bias=True)
    (g_layer): Linear(in_features=151, out_features=128, bias=True)
    (pred_layer1): Linear(in_features=516, out_features=128, bias=True)
    (pred_layer2): Linear(in_features=132, out_features=1, bias=True)
  )
) ]
2021/07/01 21:15:52: [ num of parameters: 371845 ]
2021/07/01 21:15:52: [ loading data from pt... ]
